# DIA Module

**DIA** (DSL for Interactive Agents) is a domain-specific language and runtime designed to translate
user intents and questions into tool invocations and context-aware queries. It powers goal-driven
agents that resolve missing information, recover from runtime errors, and complete complex tasks
through interactive dialogue.

The DSL is composed of five categories of nodes:

- **Intent execution** â€” structured tool calls with named parameters.
- **Slot resolution** â€” interactive prompts and LLM-based inference for missing values.
- **Control flow** â€” constructs for aborting, retrying, or redirecting execution paths.
- **Value representation** â€” concrete values, fuzzy descriptors, and references to previous slots.
- **Containers** â€” groupings of DSL elements used to sequence logic.

Each node is implemented as a Python class under [`dsl/elements`](dsl/elements), with detailed
documentation available in [`dsl/elements/README.md`](dsl/elements/README.md).

This document provides a high-level overview of the `dia` package: how DSL trees are generated,
parsed, resolved, evaluated, and integrated into interactive agents.

## ðŸ“š Table of Contents

- ðŸ“¦ [Components](#components)
- ðŸ§¾ [Parsing DSL](#parsing-dsl)
- ðŸ§­ [Resolver](#resolver)
- ðŸ§® [Evaluator](#evaluator)
- ðŸ§° [Runtime Context](#runtime-context)
- ðŸ¤– [LLM Invocation Strategy](#llm-invocation-strategy)
- ðŸš€ [Endâ€‘toâ€‘End Execution](#end-to-end-execution)

---

## ðŸ“¦ Components

The DIA system consists of three main components:

1. **Python DIA Module**  
   The core DSL engine for parsing, resolving, and evaluating structured intent trees. Handles tool
   invocation, dialog flow, slot resolution, and control-flow logic like abort and reroute.

2. **LoRA Adapter for Intent Sequencing**  
   A fine-tuned language model that translates natural language user input into DIA-compatible DSL
   expressions. This adapter serves as a foundation model and can be further fine-tuned on
   task-specific tool APIs, slot patterns, and dialog behaviors.  
   Its goal is to take a user's English request and generate a structured DSL expression ready to
   be parsed by the DIA engine.  
   ðŸ‘‰ [View Model on Hugging Face Hub](https://huggingface.co/your-model-link)

3. **Training, Testing & Evaluation Datasets**  
   A curated dataset used to train and evaluate the LoRA adapter. It includes prompts, target DSL
   expressions, slot resolution examples, and error recovery paths to help teach robust multi-turn
   behavior.  
   ðŸ‘‰ [View Dataset on Hugging Face Hub](https://huggingface.co/datasets/your-dataset-link)

---

## ðŸ§¾ Parsing DSL

The DIA parser converts a DSL expressionâ€”either handcrafted or generated by an LLMâ€”into a tree of
`DslBase` nodes. This structure is then used by the resolver and evaluator to process the user's
intent.

You can parse a DSL string using:

```python
from fifo_dev_dsl.dia.dsl.parser import parse_dsl

root = parse_dsl("retrieve_screw(count=2, length=12)")
```

In LLM-driven workflows, the DSL string is typically generated by an intent sequencer model (such
as a fine-tuned LoRA adapter), translating user prompts into structured expressions ready for
parsing.

---

## ðŸ§­ Resolver

The resolver performs **stack-based traversal** of the DSL tree. It pauses for missing values and 
resumes after each interaction, enabling stepwise multi-turn reasoning. It walks the
structure and resolves missing values using several mechanisms:

- `ASK` prompts the user for clarification.
- `QUERY_FILL`, `QUERY_USER`, and `QUERY_GATHER` query external sources via the
  `LLMRuntimeContext`.
- `PROPAGATE_SLOT` forwards values provided in the last interaction.
- `ABORT` and `ABORT_WITH_NEW_INTENTS` can replace parts of the tree.

Resolution is resumable. After each interaction request, the call stack is stored
in the `ResolutionContext` so the process can continue once the user answers.

This design is **asynchronous-friendly**: the resolver does not block or wait
for input inside its internal loop. Instead, it cleanly exits after emitting an
interaction request, allowing external systems (e.g., UI, message handlers) to
collect user input and resume resolution at a later time.

```python
from fifo_dev_dsl.dia.resolution import Resolver, ResolutionResult, Interaction, InteractionAnswer
from fifo_dev_dsl.dia.runtime import LLMRuntimeContext

runtime = LLMRuntimeContext(tools=[...], query_sources=[])
resolver = Resolver(runtime_context=runtime, prompt="retrieve some screws")

outcome = resolver(interaction_reply=None)
if outcome.result is ResolutionResult.INTERACTION_REQUESTED:
    print(outcome.interaction.message)  # e.g. "What length do you need?"
    # Pass the user answer back into the resolver
    interaction = Interaction(outcome.interaction, InteractionAnswer("12"))
    outcome = resolver(interaction)
```

Once `ResolutionResult.UNCHANGED` is returned, the DSL tree is considered **fully resolved** and can
be passed to the evaluator for execution.

> âš ï¸ **Note:** Even a fully resolved DSL tree can still trigger runtime errorsâ€”
> e.g., out-of-range tool arguments, type mismatches, or exceptions during tool
> execution. These are handled at evaluation time by the `Evaluator`, which
> wraps failures into recovery nodes (`IntentRuntimeErrorResolver`) to allow
> retry or replanning.

---

## ðŸ§® Evaluator

The **evaluator** executes a fully resolved DSL tree using **depth-first traversal**. Its purpose is
to invoke real Python tools, nest return values in composed expressions, and update the tree with
evaluation outcomes.

Each `Intent` node is replaced with an `IntentEvaluatedSuccess` node that captures the
**return value** of the tool call. This makes the evaluation **idempotent**â€”subsequent evaluations
of the same DSL skip already-executed branches.

If a tool raises an exception that is recoverable, the evaluator replaces the failed intent with an
`IntentRuntimeErrorResolver` node. This enables interactive **runtime error recovery**: the
resolver resumes resolution, explains the issue to the user, and prompts them to adapt their intent.
If the user can revise their request (e.g., choose a different screw size), the system will retry
with an updated DSL. Otherwiseâ€”if no viable alternative existsâ€”the user can choose to abort.

```python
from fifo_dev_dsl.dia.runtime import Evaluator

evaluator = Evaluator(runtime, resolver.dsl_elements)
result = evaluator.evaluate()
print(result.status, result.value)
```

Evaluation proceeds until:

- all intents are successfully executed, returning `EvaluationStatus.SUCCESS`, or
- an unrecoverable error halts execution, returning `EvaluationStatus.ABORTED_UNRECOVERABLE`, or
- a recoverable error is wrapped for retry, returning `EvaluationStatus.ABORTED_RECOVERABLE`.

See [`runtime/evaluator.py`](fifo_dev_dsl/dia/runtime/evaluator.py) for implementation details.

## ðŸ§° Runtime Context

`LLMRuntimeContext` groups all external resources available to the DSL engine during
resolution and evaluation:

- **Tool Handlers** are Python functions decorated with `@tool_handler`, exposed as
  callable intents in the DSL. These functions are matched by name and invoked with
  resolved slot arguments during evaluation.

- **Query Sources** are optional functions or services used during resolution to infer
  slot values via `QUERY_FILL`, `QUERY_GATHER`, or `QUERY_USER`. These can include
  LLM completions, search systems, or domain-specific sources like a structured
  inventory of screws available to a robotic arm, a list of tasks, or any runtime-accessible
  knowledge base. The query source is expected to return a structured YAML response
  that the resolver can use to fill in missing values.

This context also holds intermediate state (e.g., call stack, prior interactions), allowing
resolution to pause and resume across asynchronous user interactions.

```python
from fifo_dev_dsl.dia.runtime import LLMRuntimeContext
from fifo_dev_dsl.dia.tool_handler import tool_handler

class Robot:
    @tool_handler("retrieve_screw")
    def retrieve_screw(self, count: int, length: int) -> str:
        return f"retrieved {count} screws of {length}mm"

robot = Robot()
runtime = LLMRuntimeContext(
    tools=[robot.retrieve_screw],   # tool handlers exposed to the DSL
    query_sources=[]                # LLM-backed or domain-specific slot resolvers
)
```

## ðŸ¤– LLM Invocation Strategy

### LLM Invocation Pathways

`dia` uses **two types of model calls** depending on the resolution phase:

- ðŸ§  **Base model (no adapter)** â€” used for open-ended reasoning over structured runtime context
  (via `query_sources`).
- ðŸ§© **LoRA adapter** â€” used to convert user input or reasoning output into structured DSL nodes.

When resolving `QUERY_FILL`, `QUERY_USER`, or `QUERY_GATHER`, the content of the query sourcesâ€”when
availableâ€”is passed to the **base model** (not the fine-tuned LoRA adapter). This is intentional:
the goal is not to generate DSL code, but to produce a **natural-language answer** based purely on
reasoning over structured runtime data.

These queries rely purely on the base model's reasoning ability and are DSL-agnostic by design.
The model is prompted to generate an explanation first, then produce a user-facing answer based
on that reasoning. This ordering helps enforce grounded, verifiable logic before finalizing the
response.

The resulting answer is then transformed into DSL using a LoRA adapter, which specializes in
converting natural text into structured, executable form.

By cleanly separating data-based reasoning (base model) from DSL generation (adapter), the system
remains modular and more robust across domains.

### Resolution Phases and LLM Responsibilities

| Phase                          | Interactive? | Model Used        | Purpose                                                                                  | System Prompt(s)                                 |
|-------------------------------|--------------|-------------------|------------------------------------------------------------------------------------------|--------------------------------------------------|
| `QueryFill`                   | No           | Base              | Compute a value directly from structured sources                                         | `system_prompt_query_fill`                       |
| `QueryUser`                   | Yes          | Base â†’ Adapter    | **Base**: generate an answer from sources<br>**Interaction**: user reviews and responds<br>**Adapter**: convert user response into DSL | `system_prompt_query_user` â†’ `intent_sequencer` |
| `QueryGather`                 | No           | Base â†’ Adapter    | **Base**: gather auxiliary info<br>**Adapter**: generate DSL using original prompt + gathered info | `system_prompt_query_gather` â†’ `intent_sequencer` |
| `Ask`                         | Yes          | Adapter           | **Interaction**: prompt the user for a missing slot<br>**Adapter**: turn reply into DSL  | `system_prompt_slot_resolver`                    |
| `IntentRuntimeErrorResolver` | Yes          | Adapter           | **Interaction**: display runtime error and ask how to proceed<br>**Adapter**: generate updated DSL from user input | `system_prompt_error_resolver`                   |
| `resolver._process_user_prompt()` | No       | Adapter           | Convert the initial user prompt into DSL                                                 | `system_prompt_intent_sequencer`                |

> âš™ï¸ **Design rationale:** The **base model** is used exclusively for structured reasoning tasks that don't involve DSL. The **LoRA adapter** is reserved for converting natural language into structured program logic. This split avoids unnecessary fine-tuning and keeps reasoning pathways cleanly separated.

## ðŸš€ Endâ€‘toâ€‘End Execution 

### ðŸ¦¾ Robotic Arm framework

This example shows how `dia` integrates with a robotic arm framework to interpret natural language
commands, resolve missing information, and handle runtime errors through interactive user dialogue.

ðŸ§ª [View and run the demo](demo/robot_arm.py)

Key features demonstrated:
- Slot resolution with `ASK(...)` and query sources
- Runtime tool execution
- Recovery from errors using `IntentRuntimeErrorResolver`

### ðŸ§© Mini Calculator

`ReturnValue` nodes allow nesting intents so that the result of one tool feeds
another. The mini calculator below demonstrates the composition of a sum and a
multiplication.

```python
class Calc:
    @tool_handler("add")
    def add(self, a: int, b: int) -> int:
        """Add two numbers.

        Args:
            a (int): first number to add
            b (int): second number to add

        Returns:
            int: the sum of ``a`` and ``b``
        """
        return a + b

    @tool_handler("multiply")
    def multiply(self, a: int, b: int) -> int:
        """Multiply two numbers.

        Args:
            a (int): first factor
            b (int): second factor

        Returns:
            int: the product of ``a`` and ``b``
        """
        return a * b

calc = Calc()
runtime = LLMRuntimeContext(tools=[calc.add, calc.multiply], query_sources=[])
resolver = Resolver(runtime_context=runtime,
                    prompt="add 2 and 3 then multiply the result by 4")

# Step 1: resolve DSL (no loop is needed in this example because there is no missing information)
resolver.fully_resolve_in_text_mode()
dsl_elements = resolver.dsl_elements
dsl_elements.pretty_print_dsl()

# Step 2: evaluate resolved DSL (may succeed or fail)
evaluator = Evaluator(runtime, dsl_elements)
result = evaluator.evaluate()
print(result.value)  # 20
```

This prompt resolves to a DSL like `multiply(a=4, b=add(a=2, b=3))` where the inner
`add` intent is wrapped in a `ReturnValue` and its result used by `multiply`.

---

DIA provides the foundation for building dialogâ€‘driven agents. Refer to the
[DSL Elements](dsl/elements/README.md) for a full list of node types.